{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sshw0zx56XXi",
        "outputId": "c2a597ad-556e-4b73-ed50-9bb8ae057331"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import files\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from sklearn import metrics\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "from sklearn.utils import shuffle\n",
        "import os\n",
        "\n",
        "# Defining a simple LSTM Model for Text Classification\n",
        "class TextLSTM(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, num_layers, dropout):\n",
        "        super(TextLSTM, self).__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, num_layers=num_layers, dropout=dropout, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, text):\n",
        "        embedded = self.dropout(self.embedding(text))\n",
        "        output, (hidden, _) = self.lstm(embedded)\n",
        "        hidden = self.dropout(hidden[-1])\n",
        "        return self.fc(hidden)\n"
      ],
      "metadata": {
        "id": "sZKHFaws6eJM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Define a function to train the model\n",
        "# Function to train the model\n",
        "def train_model(model, iterator, optimizer, criterion, device):\n",
        "    model.train()\n",
        "    epoch_loss = 0\n",
        "    for texts, labels in iterator:\n",
        "        texts, labels = texts.to(device), labels.to(device)  # Move data to the device\n",
        "        optimizer.zero_grad()\n",
        "        predictions = model(texts)\n",
        "        loss = criterion(predictions, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        epoch_loss += loss.item()\n",
        "    return epoch_loss / len(iterator)\n",
        "\n",
        "# Function to evaluate the model\n",
        "def evaluate_model(model, iterator, criterion, device):\n",
        "    model.eval()\n",
        "    epoch_loss = 0\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "    with torch.no_grad():\n",
        "        for texts, labels in iterator:\n",
        "            texts, labels = texts.to(device), labels.to(device)  # Move data to the device\n",
        "            predictions = model(texts)\n",
        "            loss = criterion(predictions, labels)\n",
        "            epoch_loss += loss.item()\n",
        "            all_preds.append(predictions)\n",
        "            all_labels.append(labels)\n",
        "    avg_loss = epoch_loss / len(iterator)\n",
        "    eval_metrics = eval_mod(torch.cat(all_preds), torch.cat(all_labels))\n",
        "    return avg_loss, eval_metrics\n",
        "\n",
        "def eval_mod(preds, labels):\n",
        "    y_true = labels\n",
        "    y_pred_label = torch.argmax(preds, dim=1)\n",
        "    y_pred_label = y_pred_label.cpu().numpy()  # Ensuring it's a numpy array\n",
        "    y_true = y_true.cpu().numpy()  # Ensuring labels are also numpy array\n",
        "\n",
        "    accuracy = metrics.accuracy_score(y_true, y_pred_label)\n",
        "    f1_weighted = metrics.f1_score(y_true, y_pred_label, average='weighted')\n",
        "    f1_macro = metrics.f1_score(y_true, y_pred_label, average='macro')\n",
        "    f1_micro = metrics.f1_score(y_true, y_pred_label, average='micro')\n",
        "    precision_weighted = metrics.precision_score(y_true, y_pred_label, average='weighted')\n",
        "    precision_macro = metrics.precision_score(y_true, y_pred_label, average='macro')\n",
        "    precision_micro = metrics.precision_score(y_true, y_pred_label, average='micro')\n",
        "    recall_weighted = metrics.recall_score(y_true, y_pred_label, average='weighted')\n",
        "    recall_macro = metrics.recall_score(y_true, y_pred_label, average='macro')\n",
        "    recall_micro = metrics.recall_score(y_true, y_pred_label, average='micro')\n",
        "\n",
        "    results = {\"accuracy\": accuracy,\n",
        "               \"f1_weighted\": f1_weighted,\n",
        "               \"f1_macro\": f1_macro,\n",
        "               \"f1_micro\": f1_micro,\n",
        "               \"precision_weighted\": precision_weighted,\n",
        "               \"precision_macro\": precision_macro,\n",
        "               \"precision_micro\": precision_micro,\n",
        "               \"recall_weighted\": recall_weighted,\n",
        "               \"recall_macro\": recall_macro,\n",
        "               \"recall_micro\": recall_micro\n",
        "               }\n",
        "\n",
        "    return results"
      ],
      "metadata": {
        "id": "S1699yEH7qjT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.utils import shuffle\n",
        "\n",
        "def read_data(dataset_name, split_ratios=(0.8, 0.1, 0.1)):\n",
        "    data = {}\n",
        "    x, y = [], []\n",
        "\n",
        "    if dataset_name == \"r8_presplit\":\n",
        "        sentences_file = \"drive/MyDrive/CPSC_577_FP/r8_sentences_clean.txt\"\n",
        "        labels_file = \"drive/MyDrive/CPSC_577_FP/r8_labels.txt\"\n",
        "        label_pos = 2\n",
        "    elif dataset_name == \"ag_presplit\":\n",
        "        sentences_file = \"drive/MyDrive/CPSC_577_FP/ag_sentences_clean.txt\"\n",
        "        labels_file = \"drive/MyDrive/CPSC_577_FP/ag_labels.txt\"\n",
        "        label_pos = 2\n",
        "    elif dataset_name == \"twitter_asian_prejudice\":\n",
        "        sentences_file = \"drive/MyDrive/CPSC_577_FP/twitter_asian_prejudice_sentences_clean.txt\"\n",
        "        labels_file = \"drive/MyDrive/CPSC_577_FP/twitter_asian_prejudice_labels.txt\"\n",
        "        label_pos = 0\n",
        "    else:\n",
        "        raise ValueError(\"Invalid dataset name provided.\")\n",
        "\n",
        "    with open(sentences_file, \"r\", encoding=\"utf-8\") as f:\n",
        "        for line in f:\n",
        "            if line[-1] == \"\\n\":\n",
        "                line = line[:-1]\n",
        "            x.append(line.split())\n",
        "\n",
        "    with open(labels_file, \"r\", encoding=\"utf-8\") as d:\n",
        "        for line in d:\n",
        "            if line[-1] == \"\\n\":\n",
        "                line = line[:-1]\n",
        "            y.append(line.split()[label_pos])\n",
        "\n",
        "    # Shuffle data\n",
        "    x, y = shuffle(x, y, random_state=42)\n",
        "\n",
        "    # Calculate split indices\n",
        "    total_count = len(x)\n",
        "    train_end = int(split_ratios[0] * total_count)\n",
        "    valid_end = train_end + int(split_ratios[1] * total_count)\n",
        "\n",
        "    # Split data\n",
        "    data[\"train_x\"], data[\"train_y\"] = x[:train_end], y[:train_end]\n",
        "    data[\"valid_x\"], data[\"valid_y\"] = x[train_end:valid_end], y[train_end:valid_end]\n",
        "    data[\"test_x\"], data[\"test_y\"] = x[valid_end:], y[valid_end:]\n",
        "\n",
        "    return data"
      ],
      "metadata": {
        "id": "eH0i1SyN7t2E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def create_data_loader(texts, labels, batch_size, vocab, label_dict, max_len=100):\n",
        "    # Convert texts to integer sequences\n",
        "    processed_texts = [[vocab[word] if word in vocab else vocab[\"<UNK>\"] for word in text] for text in texts]\n",
        "\n",
        "    # Pad or truncate sequences\n",
        "    processed_texts = [text[:max_len] + [vocab[\"<PAD>\"]] * (max_len - len(text)) if len(text) < max_len else text[:max_len] for text in processed_texts]\n",
        "\n",
        "    # Convert labels to integers\n",
        "    processed_labels = [label_dict[label] for label in labels]\n",
        "\n",
        "    # Create tensors\n",
        "    texts_tensor = torch.tensor(processed_texts, dtype=torch.long)\n",
        "    labels_tensor = torch.tensor(processed_labels, dtype=torch.long)\n",
        "\n",
        "    # Create dataset\n",
        "    dataset = TensorDataset(texts_tensor, labels_tensor)\n",
        "    return DataLoader(dataset, batch_size=batch_size, shuffle=True)\n"
      ],
      "metadata": {
        "id": "jxWM0YAgBSyJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check if GPU is available and set the device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "89p99Pp4EnIB",
        "outputId": "aad1a3c3-4b4b-4668-cd9c-62661aa1e215"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "\n",
        "def main():\n",
        "    warnings.filterwarnings('ignore')\n",
        "    # Load data\n",
        "    dataset_name = \"r8_presplit\"\n",
        "    data = read_data(dataset_name)\n",
        "    vocab = {word: i for i, word in enumerate(set(sum(data['train_x'], [])))}  # Creating a simple vocab\n",
        "    vocab[\"<PAD>\"] = 0\n",
        "    vocab[\"<UNK>\"] = 1\n",
        "    label_dict = {label: i for i, label in enumerate(set(data['train_y']))}\n",
        "\n",
        "    # Parameters\n",
        "    vocab_size = len(vocab)\n",
        "    embedding_dim = 100\n",
        "    hidden_dim = 256\n",
        "    output_dim = 8  # Adjusted to the dataset's specific output dimensions\n",
        "    num_layers = 2\n",
        "    dropout = 0.5\n",
        "    batch_size = 64\n",
        "    num_epochs = 50\n",
        "    patience = 3  # Early stopping patience\n",
        "    num_experiments = 5\n",
        "\n",
        "    all_experiment_results = []\n",
        "\n",
        "    for exp in range(num_experiments):\n",
        "        # Create data loaders\n",
        "        train_loader = create_data_loader(data['train_x'], data['train_y'], batch_size, vocab, label_dict)\n",
        "        valid_loader = create_data_loader(data['valid_x'], data['valid_y'], batch_size, vocab, label_dict)\n",
        "\n",
        "        # Create model\n",
        "        model = TextLSTM(vocab_size, embedding_dim, hidden_dim, output_dim, num_layers, dropout).to(device)\n",
        "        learning_rate = 2e-2\n",
        "        optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "        criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "        # Early stopping mechanism\n",
        "        best_valid_loss = float('inf')\n",
        "        epochs_no_improve = 0\n",
        "\n",
        "        # Training and validation\n",
        "        for epoch in range(num_epochs):\n",
        "            start_time = time.time()\n",
        "            train_loss = train_model(model, train_loader, optimizer, criterion, device)\n",
        "            train_time = time.time() - start_time\n",
        "            valid_loss, valid_results = evaluate_model(model, valid_loader, criterion, device)\n",
        "\n",
        "            if valid_loss < best_valid_loss:\n",
        "                best_valid_loss = valid_loss\n",
        "                epochs_no_improve = 0\n",
        "                torch.save(model.state_dict(), f'/content/drive/My Drive/CPSC_577_FP/logs/LSTM/model_epoch_{epoch}_loss_{valid_loss:.4f}.pt')\n",
        "            else:\n",
        "                epochs_no_improve += 1\n",
        "                if epochs_no_improve >= patience:\n",
        "                    print(\"Early stopping triggered on experiment\", exp+1)\n",
        "                    break\n",
        "\n",
        "        all_experiment_results.append(valid_results)\n",
        "\n",
        "    # Calculate mean and standard deviation across experiments\n",
        "    final_metrics = {key: [] for key in all_experiment_results[0]}\n",
        "    for results in all_experiment_results:\n",
        "        for key in results:\n",
        "            final_metrics[key].append(results[key])\n",
        "\n",
        "    for metric in final_metrics:\n",
        "        values = np.array(final_metrics[metric])\n",
        "        mean = values.mean()\n",
        "        std = values.std()\n",
        "        print(f'{metric}: Mean={mean:.4f}, Std={std:.4f}')"
      ],
      "metadata": {
        "id": "lsQesyZn-KAJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M-UuHmFBQxQd",
        "outputId": "d9e20ffd-3a23-4dff-d015-5e8c932e5332"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Early stopping triggered on experiment 1\n",
            "Early stopping triggered on experiment 2\n",
            "Early stopping triggered on experiment 3\n",
            "Early stopping triggered on experiment 4\n",
            "Early stopping triggered on experiment 5\n",
            "accuracy: Mean=0.6240, Std=0.1025\n",
            "f1_weighted: Mean=0.5453, Std=0.1260\n",
            "f1_macro: Mean=0.1723, Std=0.0482\n",
            "f1_micro: Mean=0.6240, Std=0.1025\n",
            "precision_weighted: Mean=0.5291, Std=0.1193\n",
            "precision_macro: Mean=0.1913, Std=0.0497\n",
            "precision_micro: Mean=0.6240, Std=0.1025\n",
            "recall_weighted: Mean=0.6240, Std=0.1025\n",
            "recall_macro: Mean=0.1947, Std=0.0462\n",
            "recall_micro: Mean=0.6240, Std=0.1025\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def main1():\n",
        "    warnings.filterwarnings('ignore')\n",
        "    # Load data\n",
        "    dataset_name = \"twitter_asian_prejudice\"\n",
        "    data = read_data(dataset_name)\n",
        "    vocab = {word: i for i, word in enumerate(set(sum(data['train_x'], [])))}  # Creating a simple vocab\n",
        "    vocab[\"<PAD>\"] = 0\n",
        "    vocab[\"<UNK>\"] = 1\n",
        "    label_dict = {label: i for i, label in enumerate(set(data['train_y']))}\n",
        "\n",
        "    # Parameters\n",
        "    vocab_size = len(vocab)\n",
        "    embedding_dim = 100\n",
        "    hidden_dim = 256\n",
        "    output_dim = 5  # Adjusted to the dataset's specific output dimensions\n",
        "    num_layers = 2\n",
        "    dropout = 0.5\n",
        "    batch_size = 64\n",
        "    num_epochs = 50\n",
        "    patience = 10  # Early stopping patience\n",
        "    num_experiments = 5\n",
        "\n",
        "    all_experiment_results = []\n",
        "\n",
        "    for exp in range(num_experiments):\n",
        "        # Create data loaders\n",
        "        train_loader = create_data_loader(data['train_x'], data['train_y'], batch_size, vocab, label_dict)\n",
        "        valid_loader = create_data_loader(data['valid_x'], data['valid_y'], batch_size, vocab, label_dict)\n",
        "\n",
        "        # Create model\n",
        "        model = TextLSTM(vocab_size, embedding_dim, hidden_dim, output_dim, num_layers, dropout).to(device)\n",
        "        learning_rate = 2e-2\n",
        "        optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "        criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "        # Early stopping mechanism\n",
        "        best_valid_loss = float('inf')\n",
        "        epochs_no_improve = 0\n",
        "\n",
        "        # Training and validation\n",
        "        for epoch in range(num_epochs):\n",
        "            start_time = time.time()\n",
        "            train_loss = train_model(model, train_loader, optimizer, criterion, device)\n",
        "            train_time = time.time() - start_time\n",
        "            valid_loss, valid_results = evaluate_model(model, valid_loader, criterion, device)\n",
        "\n",
        "            if valid_loss < best_valid_loss:\n",
        "                best_valid_loss = valid_loss\n",
        "                epochs_no_improve = 0\n",
        "                torch.save(model.state_dict(), f'/content/drive/My Drive/CPSC_577_FP/logs/LSTM/model_epoch_{epoch}_loss_{valid_loss:.4f}.pt')\n",
        "            else:\n",
        "                epochs_no_improve += 1\n",
        "                if epochs_no_improve >= patience:\n",
        "                    print(\"Early stopping triggered on experiment\", exp+1)\n",
        "                    break\n",
        "\n",
        "        all_experiment_results.append(valid_results)\n",
        "\n",
        "    # Calculate mean and standard deviation across experiments\n",
        "    final_metrics = {key: [] for key in all_experiment_results[0]}\n",
        "    for results in all_experiment_results:\n",
        "        for key in results:\n",
        "            final_metrics[key].append(results[key])\n",
        "\n",
        "    for metric in final_metrics:\n",
        "        values = np.array(final_metrics[metric])\n",
        "        mean = values.mean()\n",
        "        std = values.std()\n",
        "        print(f'{metric}: Mean={mean:.6f}, Std={std:.6f}')"
      ],
      "metadata": {
        "id": "LntjFutMAy8g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
        "main1()  # Run your main function again"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F_8hWHUJFUv5",
        "outputId": "98c10099-29b7-4587-9db1-906c7136da69"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Early stopping triggered on experiment 1\n",
            "Early stopping triggered on experiment 2\n",
            "Early stopping triggered on experiment 3\n",
            "Early stopping triggered on experiment 4\n",
            "Early stopping triggered on experiment 5\n",
            "accuracy: Mean=0.679000, Std=0.000000\n",
            "f1_weighted: Mean=0.549185, Std=0.000000\n",
            "f1_macro: Mean=0.161763, Std=0.000000\n",
            "f1_micro: Mean=0.679000, Std=0.000000\n",
            "precision_weighted: Mean=0.461041, Std=0.000000\n",
            "precision_macro: Mean=0.135800, Std=0.000000\n",
            "precision_micro: Mean=0.679000, Std=0.000000\n",
            "recall_weighted: Mean=0.679000, Std=0.000000\n",
            "recall_macro: Mean=0.200000, Std=0.000000\n",
            "recall_micro: Mean=0.679000, Std=0.000000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xcc8AHX5FwlA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}